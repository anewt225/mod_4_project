{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Estate Consulting Proposal\n",
    "Flatiron Mod 4 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This project, a consulting proposal for a real estate investment firm, uses Time Series Analysis to present the top 5 zip codes for the firm to invest in in the US. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadMe Navigation\n",
    "\n",
    "1. [Repository Navigation](#Repository-Navigation)\n",
    "\n",
    "2. [Business Understanding](#Business-Understanding)\n",
    "\n",
    "3. [Data Understanding](#Data-Understanding)\n",
    "\n",
    "4. [Predictive Analysis](#Predictive-Analysis)\n",
    "    1. Model Performance\n",
    "    2. Prediction\n",
    "\n",
    "5. [Conclusion](#Conclusion)\n",
    "    1. Recommendations\n",
    "    2. Areas for Growth\n",
    "\n",
    "8. [Project Info](#Project-Info)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repository Navigation\n",
    "- [DATA:](data)\n",
    "    - [Raw Folder](data/raw)\n",
    "        - [Original Dataset](data/raw/zillow_data.csv)\n",
    "    - [Processed Folder](data/processed)\n",
    "        - [Original Dataset Organized by Zip Codes](data/processed/zipcodes.pkl)\n",
    "        - [Modified Zip Codes for EDA](data/wip/zip_df.pkl)\n",
    "        - [First Attempt Median Predictions](data/processed/low_median_previous_df.pkl)\n",
    "        - [Low Median Test Set](data/processed/low_median_test_df.pkl)\n",
    "        - [Low Median Train Set](data/processed/low_median_train_df.pkl)\n",
    "        - [Low Median Predictions](data/processed/low_medians_predictions_df.pkl)\n",
    "        - [Predictions for High Median Range](data/processed/high_medians_predictions_df.pkl)\n",
    "        - [Error evaluations](data/processed/errors_df.pkl)\n",
    "    - [Works in Progress Folder](data/wip)\n",
    "    \n",
    "- [SRC:](src)\n",
    "    - [Python Initilization file](src/__init__.py)\n",
    "    - [Script for Data Cleaning](src/data_cleaning.py)\n",
    "    - [Script for Modeling](src/modeling.py)\n",
    "        \n",
    "- [FIGURES:](figures)\n",
    "    - Visualizations used/created throughout the project.\n",
    "    \n",
    "- [MODELS:](models)\n",
    "    - Pickled files storing data relevant to the model creation.\n",
    "\n",
    "- [NOTEBOOKS:](notebooks)\n",
    "    - [Preliminary Exploratory Data Analysis](notebooks/eda-prelim.ipynb)\n",
    "    - [EDA for Models](notebooks/eda-models.ipynb)\n",
    "    - [Models](notebooks/models.ipynb)\n",
    "    - [Visualizations](notebooks/visualizations)\n",
    "\n",
    "- [PRESENTATION:](presentation)\n",
    "    - [PDF](presentation/mod_4_real_estate_project.pdf)\n",
    "    - [Powerpoint](presentation/mod_4_project.pptx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "The  business context for this project is relatively straightforward - select 5 top zip codes for investment within the United States, based on a dataset given from Zillow.\n",
    "\n",
    "**GOAL: Predict top 5 zip code in United States for real estate firm to invest in.**\n",
    "\n",
    "To further clarify this goal, we use a risk-adjusted Return on Investment (ROI) as our metric for \"top\":\n",
    "\n",
    "- **ROI:** Predicted Price Increase / Initial Investment\n",
    "- **Risk-adjustment:** After some exploratory data analysis (EDA), we define risk-adjusted by limiting the range of zip codes to those without large ranges of error in the model prediction.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The dataset for this project came from Zillow, with the following data from 1996 through 2018:\n",
    "- RegionID (Zip Code)\n",
    "- RegionName (Zillow-defined code)\n",
    "- City\n",
    "- State\n",
    "- Metro (Metropolitan Area)\n",
    "- CountyName\n",
    "- Size Rank (Ordinal City size categories)\n",
    "- Monthly Median Prices\n",
    "\n",
    "An overview of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/zillow_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d7be498aa500>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/raw/zillow_data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2-1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2-1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2-1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2-1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tf2-1\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/zillow_data.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/raw/zillow_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nationwide median price looked like this:\n",
    "\n",
    "![Nationwide Median](figures/nationwide.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Analysis**\n",
    "- Given the monthly price measurements, we used **Time Series Analysis** to gain a better understanding for the patterns in the data that would impact our predictions.\n",
    "\n",
    "- Additionally, we restrict our model construction to data ***after the 2008 recession,*** since the variation due to the anomaly is already known, and our model will perform better without having to account for such a huge fluctuation.\n",
    "\n",
    "- Finally, given computational resource restrictions, we ***limit our dataset*** to the 60 zip codes with the largest ROI in a 5-year rolling window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Analysis\n",
    "\n",
    "### Time Series Analysis\n",
    "By using time-series analysis, we can use time-linked historical data to discover which areas have the highest ROI, which is a time-delta linked indicator. This particular method enables median price value prediction.\n",
    "\n",
    "In order to use this model, we must eliminate noise in the data in order to make accurate predictions, based on the assumptions of the model:\n",
    "\n",
    "1. **Stationarity** - Ensures that the distribution of data does not change over time\n",
    "\n",
    "2. **Seasonality** - Adjusting for regular fluctuations based on a fixed interval (e.g., higher prices in spring, lower prices in fall)\n",
    "\n",
    "3. **Autocorrelation** - Adjusts for covariance of time-series with itself, based on its variables.\n",
    "\n",
    "4. **Trend** - Adjusts for long-term trends such as overall increase, overall decrease.\n",
    "\n",
    "The goal of these limitations is to remove the time-based impacts upon the median price to discover any potential underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric\n",
    "\n",
    "\n",
    "###  Model Selection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations:\n",
    "\n",
    "1. Higher Median Investment\n",
    "\n",
    "2. Lower Median Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Areas for Growth:\n",
    "\n",
    "#### Include Adjacent Data Resources\n",
    "With additional time, we would incorporate other ways to measure \"top 5\" and ROI, including usin other sources like:\n",
    "- Zillow Rent Data\n",
    "- Competitor Median Prices\n",
    "- AirBnB rental increases/returns\n",
    "\n",
    "#### Improve Model\n",
    "The model was significantly limited due to time and resource constraints. With more of each, we could:\n",
    "- Fit model to all zip codes, not just limited set\n",
    "- Consider grouping zip codes and areas into better tiers\n",
    "- Train model on nationwide data for the ability to \"drill-down\" more precisely\n",
    "\n",
    "#### Extend Time Frame for Analysis\n",
    "With more data, we could predict longer term trends instead of just the limited 5-year period we selected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Info\n",
    "\n",
    "Contributors: __[Alexander](https://www.linkedin.com/in/anewt/)__ __[Newton](https://github.com/anewt225)__, __[Jake](https://www.linkedin.com/in/jake-miller-brooks-a37a64106//)__ __[Miller Brooks](https://github.com/jmillerbrooks)__\n",
    "\n",
    "Languages  : Python\n",
    "\n",
    "Tools/IDE  : Git, Command Line (Windows), Anaconda, Jupyter Notebook / Jupyter Lab, Google Slides\n",
    "\n",
    "Libraries  : numpy, pandas, matplotlib, seaborn, scikit-learn, statsmodels \n",
    "\n",
    "Duration   : August 2020\n",
    "Last Update: 08.24.2020\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "307.975px",
    "width": "377.975px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "485.926px",
    "left": "1137.79px",
    "top": "222.926px",
    "width": "284.433px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
